"""
storage_manager.py - å­˜å‚¨ç®¡ç†ä¸æ—¶é—´ç¼éš™è¡¥å…¨

æ ¸å¿ƒèŒè´£:
1. ç»´æŠ¤ SQLite æ•°æ®åº“ (raw_content.db)
2. ç®¡ç†æ—¶é—´è¦†ç›–æ—¥å¿— (manifest.json)
3. è®¡ç®—æ•°æ®ç¼ºå£å¹¶åˆå¹¶åŒºé—´
"""

import json
import os
import sqlite3
from datetime import datetime, timedelta
from typing import List, Tuple, Optional, Union
from pathlib import Path


class StorageManager:
    """å­˜å‚¨ç®¡ç†å™¨ï¼šç»´æŠ¤ SQLite æ•°æ®åº“ä¸æ—¶é—´çª—å£è¦†ç›–æ—¥å¿—"""
    
    def __init__(self, data_dir: str = None):
        if data_dir is None:
            data_dir = Path(__file__).parent.parent / "data"
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.db_path = self.data_dir / "raw_content.db"
        self.manifest_path = self.data_dir / "manifest.json"
        
        self._init_database()
        self._init_manifest()
    
    def _init_database(self):
        """åˆå§‹åŒ– SQLite æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¡¨ (åŒ…å«æ–°å­—æ®µ)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS content (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tweet_id TEXT UNIQUE,
                author TEXT NOT NULL,
                text TEXT,
                publish_time TEXT,
                url TEXT,
                platform TEXT DEFAULT 'twitter',
                is_retweet INTEGER DEFAULT 0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                
                -- æ–°å¢å­—æ®µ
                like_count INTEGER DEFAULT 0,
                retweet_count INTEGER DEFAULT 0,
                reply_count INTEGER DEFAULT 0,
                quote_count INTEGER DEFAULT 0,
                view_count INTEGER DEFAULT 0,
                lang TEXT,
                author_followers INTEGER DEFAULT 0
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•åŠ é€ŸæŸ¥è¯¢
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_author ON content(author)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_publish_time ON content(publish_time)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_platform ON content(platform)')
        
        # åˆ›å»ºæ ‡æ³¨ Schema å…ƒæ•°æ®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS annotation_schemas (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                schema_name TEXT UNIQUE NOT NULL,
                description TEXT,
                fields_json TEXT NOT NULL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        
        # å°è¯•è¿ç§»ï¼ˆé’ˆå¯¹æ—§è¡¨ç»“æ„ï¼‰
        self._migrate_database()
        
    def _migrate_database(self):
        """è¿ç§»æ•°æ®åº“ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        columns_to_add = [
            ("like_count", "INTEGER DEFAULT 0"),
            ("retweet_count", "INTEGER DEFAULT 0"),
            ("reply_count", "INTEGER DEFAULT 0"),
            ("quote_count", "INTEGER DEFAULT 0"),
            ("view_count", "INTEGER DEFAULT 0"),
            ("lang", "TEXT"),
            ("author_followers", "INTEGER DEFAULT 0")
        ]
        
        try:
            # è·å–ç°æœ‰åˆ—
            cursor.execute("PRAGMA table_info(content)")
            existing_columns = {row[1] for row in cursor.fetchall()}
            
            for col_name, col_type in columns_to_add:
                if col_name not in existing_columns:
                    print(f"ğŸ”§ æ­£åœ¨è¿ç§»æ•°æ®åº“ï¼Œæ·»åŠ åˆ—: {col_name}")
                    cursor.execute(f"ALTER TABLE content ADD COLUMN {col_name} {col_type}")
            
            conn.commit()
        except Exception as e:
            print(f"æ•°æ®åº“è¿ç§»è­¦å‘Š: {e}")
        finally:
            conn.close()
    
    def _init_manifest(self):
        """åˆå§‹åŒ–æ—¶é—´è¦†ç›–æ—¥å¿—"""
        if not self.manifest_path.exists():
            with open(self.manifest_path, 'w', encoding='utf-8') as f:
                json.dump({}, f)
    
    def _load_manifest(self) -> dict:
        """åŠ è½½ manifest.json"""
        if not self.manifest_path.exists():
            return {}
        with open(self.manifest_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _save_manifest(self, manifest: dict):
        """ä¿å­˜ manifest.json"""
        with open(self.manifest_path, 'w', encoding='utf-8') as f:
            json.dump(manifest, f, ensure_ascii=False, indent=2)
    
    def save_tweets(self, tweets: List[dict]) -> int:
        """
        ä¿å­˜æ¨æ–‡åˆ°æ•°æ®åº“
        
        Args:
            tweets: æ¨æ–‡åˆ—è¡¨
            
        Returns:
            æˆåŠŸæ’å…¥çš„æ•°é‡
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        inserted = 0
        for tweet in tweets:
            try:
                # æå– metrics
                metrics = tweet.get('metrics', {})
                metadata = tweet.get('metadata', {})
                
                cursor.execute('''
                    INSERT OR REPLACE INTO content 
                    (tweet_id, author, text, publish_time, url, platform, is_retweet,
                     like_count, retweet_count, reply_count, quote_count, view_count, lang, author_followers)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    tweet.get('content_id') or tweet.get('tweet_id'), # å…¼å®¹ä¸¤ç§ key
                    tweet.get('author'),
                    tweet.get('text'),
                    tweet.get('publish_time') or tweet.get('created_at'),
                    tweet.get('url'),
                    tweet.get('platform', 'twitter'),
                    1 if tweet.get('is_retweet') else 0,
                    
                    # æ–°å­—æ®µ
                    metrics.get('likes', 0),
                    metrics.get('retweets', 0),
                    metrics.get('replies', 0),
                    metrics.get('quotes', 0),
                    metrics.get('views', 0),
                    tweet.get('lang', ''),
                    metadata.get('author_followers', 0)
                ))
                if cursor.rowcount > 0:
                    inserted += 1
            except sqlite3.Error as e:
                print(f"Error inserting tweet {tweet.get('content_id')}: {e}")
        
        conn.commit()
        conn.close()
        return inserted
    
    # ==================== Schema ç®¡ç†æ–¹æ³• ====================
    
    def save_schema(self, schema: dict):
        """
        ä¿å­˜æ ‡æ³¨ Schema åˆ°å…ƒæ•°æ®è¡¨
        
        Args:
            schema: Schema å®šä¹‰å­—å…¸
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO annotation_schemas (schema_name, description, fields_json)
                VALUES (?, ?, ?)
            ''', (
                schema['schema_name'],
                schema.get('description', ''),
                json.dumps(schema['fields'], ensure_ascii=False)
            ))
            conn.commit()
            print(f"âœ… Schema '{schema['schema_name']}' å·²ä¿å­˜")
        except Exception as e:
            print(f"âŒ ä¿å­˜ Schema å¤±è´¥: {e}")
        finally:
            conn.close()
    
    def load_schema(self, schema_name: str) -> dict:
        """
        åŠ è½½æ ‡æ³¨ Schema
        
        Args:
            schema_name: Schema åç§°
            
        Returns:
            Schema å®šä¹‰å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT schema_name, description, fields_json
            FROM annotation_schemas
            WHERE schema_name = ?
        ''', (schema_name,))
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return None
        
        return {
            'schema_name': row[0],
            'description': row[1],
            'fields': json.loads(row[2])
        }
    
    def list_schemas(self) -> list:
        """
        åˆ—å‡ºæ‰€æœ‰å·²ä¿å­˜çš„ Schema
        
        Returns:
            Schema åç§°å’Œæè¿°çš„åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT schema_name, description, created_at
            FROM annotation_schemas
            ORDER BY created_at DESC
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        return [{
            'schema_name': row[0],
            'description': row[1],
            'created_at': row[2]
        } for row in rows]
    
    def get_column_names(self) -> set:
        """
        è·å– content è¡¨çš„æ‰€æœ‰åˆ—å
        
        Returns:
            åˆ—åé›†åˆ
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("PRAGMA table_info(content)")
        columns = {row[1] for row in cursor.fetchall()}
        
        conn.close()
        return columns
    
    def get_tweets(
        self, 
        author: Union[str, List[str], None] = None, 
        start_date: str = None, 
        end_date: str = None,
        keyword: str = None,
        limit: int = None
    ) -> List[dict]:
        """
        ä»æ•°æ®åº“æ£€ç´¢æ¨æ–‡
        
        Args:
            author: ä½œè€… screen_name (æ”¯æŒå•ä¸ªå­—ç¬¦ä¸²æˆ–åˆ—è¡¨)
            start_date: èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            keyword: å…¨æ–‡æœç´¢å…³é”®è¯
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            æ¨æ–‡åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        query = "SELECT * FROM content WHERE 1=1"
        params = []
        
        if author:
            if isinstance(author, list):
                if author:
                    placeholders = ', '.join(['?'] * len(author))
                    query += f" AND author IN ({placeholders})"
                    params.extend(author)
            else:
                query += " AND author = ?"
                params.append(author)
        
        if start_date:
            query += " AND publish_time >= ?"
            params.append(start_date)
        
        if end_date:
            query += " AND publish_time <= ?"
            params.append(end_date + "T23:59:59")
        
        if keyword:
            query += " AND text LIKE ?"
            params.append(f"%{keyword}%")
        
        query += " ORDER BY publish_time DESC"
        
        if limit:
            query += f" LIMIT {limit}"
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()
        
        return [dict(row) for row in rows]
    
    # ==================== æ ¸å¿ƒ: æ—¶é—´ç¼éš™ç®—æ³• ====================
    
    def get_missing_ranges(
        self, 
        handle: str, 
        start_date: str, 
        end_date: str
    ) -> List[Tuple[str, str]]:
        """
        è®¡ç®—æŒ‡å®šæ—¶é—´åŒºé—´å†…ç¼ºå¤±çš„æ•°æ®èŒƒå›´
        
        è¿™æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒç®—æ³•ï¼Œè´Ÿè´£æ¯”å¯¹ç”¨æˆ·è¯·æ±‚çš„æ—¶é—´åŒºé—´ä¸å·²å­˜å‚¨åŒºé—´ï¼Œ
        è¿”å›çœŸæ­£éœ€è¦çˆ¬å–çš„ç¼ºå¤±ç‰‡æ®µã€‚
        
        Args:
            handle: åšä¸»çš„ screen_name
            start_date: è¯·æ±‚çš„èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: è¯·æ±‚çš„ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            ç¼ºå¤±åŒºé—´åˆ—è¡¨ï¼Œå¦‚ [("2024-01-01", "2024-01-04"), ("2024-01-21", "2024-01-30")]
        
        Example:
            ç”¨æˆ·è¯·æ±‚ [1.1, 1.30]
            æœ¬åœ°å·²æœ‰ [1.5, 1.20]
            è¿”å› [(1.1, 1.4), (1.21, 1.30)]
        """
        manifest = self._load_manifest()
        
        # è·å–è¯¥åšä¸»å·²å­˜å‚¨çš„åŒºé—´åˆ—è¡¨
        stored_ranges = manifest.get(handle, [])
        
        if not stored_ranges:
            # æ²¡æœ‰ä»»ä½•å­˜å‚¨ï¼Œè¿”å›å®Œæ•´è¯·æ±‚åŒºé—´
            return [(start_date, end_date)]
        
        # è½¬æ¢ä¸ºæ—¥æœŸå¯¹è±¡ä¾¿äºè®¡ç®—
        req_start = datetime.strptime(start_date, "%Y-%m-%d")
        req_end = datetime.strptime(end_date, "%Y-%m-%d")
        
        # å°†å·²å­˜å‚¨åŒºé—´æ’åº
        stored = []
        for rng in stored_ranges:
            s = datetime.strptime(rng[0], "%Y-%m-%d")
            e = datetime.strptime(rng[1], "%Y-%m-%d")
            stored.append((s, e))
        stored.sort(key=lambda x: x[0])
        
        # è®¡ç®—ç¼ºå£
        missing = []
        current = req_start
        
        for s_start, s_end in stored:
            # å¦‚æœå½“å‰æŒ‡é’ˆå·²ç»è¶…è¿‡è¯·æ±‚ç»“æŸï¼Œåœæ­¢
            if current > req_end:
                break
            
            # å­˜å‚¨åŒºé—´åœ¨è¯·æ±‚åŒºé—´ä¹‹å‰ï¼Œè·³è¿‡
            if s_end < current:
                continue
            
            # å­˜å‚¨åŒºé—´åœ¨è¯·æ±‚åŒºé—´ä¹‹åï¼Œè®°å½•ç¼ºå£åˆ°å­˜å‚¨å¼€å§‹
            if s_start > current:
                gap_end = min(s_start - timedelta(days=1), req_end)
                if gap_end >= current:
                    missing.append((
                        current.strftime("%Y-%m-%d"),
                        gap_end.strftime("%Y-%m-%d")
                    ))
            
            # æ›´æ–°å½“å‰æŒ‡é’ˆåˆ°å·²å­˜å‚¨åŒºé—´ç»“æŸçš„ä¸‹ä¸€å¤©
            current = max(current, s_end + timedelta(days=1))
        
        # æ£€æŸ¥å°¾éƒ¨ç¼ºå£
        if current <= req_end:
            missing.append((
                current.strftime("%Y-%m-%d"),
                req_end.strftime("%Y-%m-%d")
            ))
        
        return missing
    
    def merge_intervals(self, intervals: List[Tuple[str, str]]) -> List[Tuple[str, str]]:
        """
        åˆå¹¶é‡å çš„æ—¶é—´åŒºé—´
        
        Args:
            intervals: åŒºé—´åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (start_date, end_date)
            
        Returns:
            åˆå¹¶åçš„åŒºé—´åˆ—è¡¨
        
        Example:
            è¾“å…¥: [("2024-01-01", "2024-01-10"), ("2024-01-08", "2024-01-20")]
            è¾“å‡º: [("2024-01-01", "2024-01-20")]
        """
        if not intervals:
            return []
        
        # è½¬æ¢ä¸ºæ—¥æœŸå¯¹è±¡
        date_intervals = []
        for start, end in intervals:
            s = datetime.strptime(start, "%Y-%m-%d")
            e = datetime.strptime(end, "%Y-%m-%d")
            date_intervals.append((s, e))
        
        # æŒ‰èµ·å§‹æ—¥æœŸæ’åº
        date_intervals.sort(key=lambda x: x[0])
        
        merged = [date_intervals[0]]
        
        for current_start, current_end in date_intervals[1:]:
            last_start, last_end = merged[-1]
            
            # å¦‚æœå½“å‰åŒºé—´ä¸ä¸Šä¸€ä¸ªé‡å æˆ–ç›¸é‚»ï¼ˆå·®1å¤©ä¹Ÿç®—ç›¸é‚»ï¼‰
            if current_start <= last_end + timedelta(days=1):
                # åˆå¹¶
                merged[-1] = (last_start, max(last_end, current_end))
            else:
                # ä¸é‡å ï¼Œæ–°å¢
                merged.append((current_start, current_end))
        
        # è½¬å›å­—ç¬¦ä¸²æ ¼å¼
        return [(s.strftime("%Y-%m-%d"), e.strftime("%Y-%m-%d")) for s, e in merged]
    
    def update_manifest(self, handle: str, new_range: Tuple[str, str]):
        """
        æ›´æ–° manifest.jsonï¼Œæ·»åŠ æ–°æŠ“å–çš„æ—¶é—´èŒƒå›´å¹¶åˆå¹¶
        
        Args:
            handle: åšä¸»çš„ screen_name
            new_range: æ–°æŠ“å–çš„åŒºé—´ (start_date, end_date)
        """
        manifest = self._load_manifest()
        
        existing = manifest.get(handle, [])
        # è½¬æ¢ä¸ºå…ƒç»„åˆ—è¡¨
        existing = [tuple(r) for r in existing]
        existing.append(new_range)
        
        # åˆå¹¶åŒºé—´
        merged = self.merge_intervals(existing)
        
        manifest[handle] = merged
        self._save_manifest(manifest)
    
    def get_coverage(self, handle: str) -> List[Tuple[str, str]]:
        """è·å–æŸåšä¸»çš„å·²è¦†ç›–æ—¶é—´åŒºé—´"""
        manifest = self._load_manifest()
        return manifest.get(handle, [])


# ==================== æµ‹è¯•ä»£ç  ====================
if __name__ == "__main__":
    sm = StorageManager()
    
    # æµ‹è¯•åŒºé—´åˆå¹¶
    intervals = [
        ("2024-01-01", "2024-01-10"),
        ("2024-01-08", "2024-01-20"),
        ("2024-01-25", "2024-01-30")
    ]
    merged = sm.merge_intervals(intervals)
    print(f"åˆå¹¶ç»“æœ: {merged}")
    # é¢„æœŸ: [("2024-01-01", "2024-01-20"), ("2024-01-25", "2024-01-30")]
    
    # æµ‹è¯•ç¼ºå£è®¡ç®—
    sm.update_manifest("test_user", ("2024-01-05", "2024-01-20"))
    gaps = sm.get_missing_ranges("test_user", "2024-01-01", "2024-01-30")
    print(f"ç¼ºå£åŒºé—´: {gaps}")
    # é¢„æœŸ: [("2024-01-01", "2024-01-04"), ("2024-01-21", "2024-01-30")]
